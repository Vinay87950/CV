{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "portable-honolulu",
   "metadata": {},
   "source": [
    "## DEL-03 Programming Excercise - Multi-Layer Perceptron - Forward Propagation\n",
    "### (created by Prof. Dr.-Ing. Christian Bergler & Prof. Dr. Fabian Brunner)\n",
    "\n",
    "Documentation: **Python-Bibliothek Pandas** - https://pandas.pydata.org/docs/\n",
    "\n",
    "Documentation: **Numpy** - https://numpy.org/doc/\n",
    "\n",
    "Documentation: **Sklearn** - https://scikit-learn.org/stable/index.html\n",
    "\n",
    "Documentation: **Matplotlib** - Documentation: https://matplotlib.org/stable/index.html\n",
    "\n",
    "Documentation: **Matplotlib** - Graphics Gallery: https://matplotlib.org/2.0.2/gallery.html\n",
    "\n",
    "Additional Documentation: **Python Tutorial** - https://docs.python.org/3/tutorial/\n",
    "\n",
    "Additional Documentation: **Matthes Eric, \"Python crash course: A hands-on, project-based introduction to programming\"**, ISBN: 978-1-59327-603-4, Â©2023 no starch press  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "775f02d0-0a43-4e74-ba20-2dd6e31d4c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf35aa-e63a-4614-82fd-bdd0930bc58e",
   "metadata": {},
   "source": [
    "### Task DEL-03-1 (Sigmoid Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c36ae757-3573-4d06-a17c-85dc653400fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-abraham",
   "metadata": {},
   "source": [
    "### Task DEL-03-2 (Softmax Activation Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "374b557d-ae54-4d6f-a28b-9e77c7a7b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(O):\n",
    "    O_exp = np.exp(O - np.max(O, axis=1, keepdims=True))\n",
    "    partition = O_exp.sum(axis=1, keepdims=True)\n",
    "    return O_exp / partition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b155c-caf8-4e0a-88d8-360297444f30",
   "metadata": {},
   "source": [
    "### Task DEL-03-3 (Implementation Multi-Layer Perceptron for Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9712ba-b48e-4229-8a2e-4bdb22ce3317",
   "metadata": {},
   "source": [
    "In this and the next exercise, an `Multi-Layer Perceptron (Deep Feed Forward Neural Network)`  for classification is to be implemented from scratch. The topology of the network is to be specified using a list called `nodes_per_layer`. The $i$th entry specifies how many nodes the $i$th layer consists of. The number of layers can be arbitrary. The number of classes corresponds to the number of nodes in the output layer. \n",
    "\n",
    "Example: ``nodes_per_layer = [4,5,3]`` would realize a network with 4 nodes in the input layer, 5 nodes in the hidden layer and 3 nodes in the output layer.\n",
    "\n",
    "\n",
    "In the current exercise, the `forward propagation` is to be realized first. To do this, complete the following methods of the ``DeepFeedForward`` class. In the next exercise, `backward propagation` will be implemented in order to realize model training using the gradient method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "260573fe-8ca2-4d53-8df7-5b3a5bf89066",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFeedForward:\n",
    "    def __init__(self, nodes_per_layer, lr=1.0, num_iter = 100):\n",
    "        self.learning_rate = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.n_layers = len(nodes_per_layer) #number of layers\n",
    "        self.nodes_per_layer = nodes_per_layer #list containing the number of nodes for each layer\n",
    "        self.n_classes = nodes_per_layer[-1] #number of output units (=number of classes for classification)\n",
    "        self.weight_matrices = [] #in this list, the weight matrices will be stored\n",
    "        self.bias_vectors = [] #in this list, the bias vectors will be stored\n",
    "   \n",
    "    def initialize_weights(self):\n",
    "        \"\"\"\n",
    "        When this function is called, the weight matrices and bias vectors are \n",
    "        initialized with random normally distributed numbers and stored in the instance parameters weight_matrices and bias_vectors\n",
    "        For each layer (except the input layer), one weight matrix and one bias vector is needed.\n",
    "        The dimensions of the matrices depend on the number of units of the layers.\n",
    "        \"\"\" \n",
    "        self.weight_matrices = []\n",
    "        self.bias_vectors = []\n",
    "        #TODO\n",
    "        for i in range(1, self.n_layers):\n",
    "            input_size = self.nodes_per_layer[i-1]\n",
    "            output_size = self.nodes_per_layer[i]\n",
    "            weight_matrix = np.random.randn(input_size, output_size)\n",
    "            bias_vector = np.random.randn(output_size)\n",
    "            self.weight_matrices.append(weight_matrix)\n",
    "            self.bias_vectors.append(bias_vector)\n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        model function to perform the forward pass through the net for all samples in the batch X\n",
    "        \n",
    "        In each layer except the output layer, sigmoid activation is used. \n",
    "        In the output layer, softmax activation is used.\n",
    "        \n",
    "        :param X: batch of training data of dimension n_samples x n_features\n",
    "        :type X: numpy array\n",
    "        :return: array containing the predicted scores for all samples of the batch X (dimension: n_samples x n_classes)\n",
    "        :rtype: numpy array\n",
    "        \"\"\" \n",
    "        #TODO\n",
    "        layer_inputs = []\n",
    "        layer_outputs = []\n",
    "\n",
    "        A = X\n",
    "        for i in range(self.n_layers - 1):\n",
    "            Z = np.dot(A, self.weight_matrices[i]) + self.bias_vectors[i]\n",
    "            layer_inputs.append(Z)\n",
    "            if i == self.n_layers - 2:\n",
    "                A = self.softmax(Z)\n",
    "            else:\n",
    "                A = self.sigmoid(Z)\n",
    "            layer_outputs.append(A)\n",
    "\n",
    "        self.layer_outputs = layer_outputs\n",
    "        self.layer_inputs = layer_inputs\n",
    "\n",
    "        return layer_outputs[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-scroll",
   "metadata": {},
   "source": [
    "### Task DEL-03-4 (Testing Implemented Forward Propagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-status",
   "metadata": {},
   "source": [
    "- Create a new `DeepFeedForward` object with `4 input neurons, 5 hidden neurons, and 3 output neurons`\n",
    "- Initialize `weights` and `biases`\n",
    "- Compute the `foward` path\n",
    "- Return the `shape` ov `y_hat` and the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c01fee0-539c-4b54-aafe-5fc990c318af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 3), array([[0.92676573, 0.00408748, 0.06914679]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DeepFeedForward:\n",
    "    def __init__(self, nodes_per_layer, lr=1.0, num_iter=100):\n",
    "        self.learning_rate = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.n_layers = len(nodes_per_layer)  # number of layers\n",
    "        self.nodes_per_layer = nodes_per_layer  # list containing the number of nodes for each layer\n",
    "        self.n_classes = nodes_per_layer[-1]  # number of output units (=number of classes for classification)\n",
    "        self.weight_matrices = []  # in this list, the weight matrices will be stored\n",
    "        self.bias_vectors = []  # in this list, the bias vectors will be stored\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        \"\"\"\n",
    "        When this function is called, the weight matrices and bias vectors are \n",
    "        initialized with random normally distributed numbers and stored in the instance parameters weight_matrices and bias_vectors.\n",
    "        For each layer (except the input layer), one weight matrix and one bias vector is needed.\n",
    "        The dimensions of the matrices depend on the number of units of the layers.\n",
    "        \"\"\"\n",
    "        self.weight_matrices = []\n",
    "        self.bias_vectors = []\n",
    "        for i in range(1, self.n_layers):\n",
    "            input_size = self.nodes_per_layer[i - 1]\n",
    "            output_size = self.nodes_per_layer[i]\n",
    "            weight_matrix = np.random.randn(input_size, output_size)\n",
    "            bias_vector = np.random.randn(output_size)\n",
    "            self.weight_matrices.append(weight_matrix)\n",
    "            self.bias_vectors.append(bias_vector)\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Model function to perform the forward pass through the net for all samples in the batch X.\n",
    "        \n",
    "        In each layer except the output layer, sigmoid activation is used. \n",
    "        In the output layer, softmax activation is used.\n",
    "        \n",
    "        :param X: batch of training data of dimension n_samples x n_features\n",
    "        :type X: numpy array\n",
    "        :return: array containing the predicted scores for all samples of the batch X (dimension: n_samples x n_classes)\n",
    "        :rtype: numpy array\n",
    "        \"\"\"\n",
    "        layer_inputs = []\n",
    "        layer_outputs = []\n",
    "\n",
    "        A = X\n",
    "        for i in range(self.n_layers - 1):\n",
    "            Z = np.dot(A, self.weight_matrices[i]) + self.bias_vectors[i]\n",
    "            layer_inputs.append(Z)\n",
    "            if i == self.n_layers - 2:\n",
    "                A = self.softmax(Z)\n",
    "            else:\n",
    "                A = self.sigmoid(Z)\n",
    "            layer_outputs.append(A)\n",
    "\n",
    "        self.layer_outputs = layer_outputs\n",
    "        self.layer_inputs = layer_inputs\n",
    "\n",
    "        return layer_outputs[-1]\n",
    "\n",
    "# Define the architecture of the neural network\n",
    "nodes_per_layer = [4, 5, 3]\n",
    "\n",
    "# Initialize the DeepFeedForward object\n",
    "dff = DeepFeedForward(nodes_per_layer)\n",
    "\n",
    "# Initialize weights and biases\n",
    "dff.initialize_weights()\n",
    "\n",
    "# Create some input data with 4 features\n",
    "X_test = np.random.randn(1, 4)  # single sample with 4 features\n",
    "\n",
    "# Compute the forward pass\n",
    "y_hat = dff.forward(X_test)\n",
    "\n",
    "# Return the shape of y_hat and its content\n",
    "y_hat_shape = y_hat.shape\n",
    "y_hat_content = y_hat\n",
    "\n",
    "y_hat_shape, y_hat_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "animal-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data \n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "identical-conflict",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DeepFeedForward.__init__() missing 1 required positional argument: 'nodes_per_layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m      3\u001b[0m num_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m----> 4\u001b[0m forward \u001b[38;5;241m=\u001b[39m \u001b[43mDeepFeedForward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iterations\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: DeepFeedForward.__init__() missing 1 required positional argument: 'nodes_per_layer'"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "learning_rate = 1.0\n",
    "num_iterations = 100\n",
    "nodes_per_layer = \n",
    "forward = DeepFeedForward(lr=learning_rate, num_iter=num_iterations,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-heater",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d16245f5-97bf-4e83-a6d3-bcdc8fc256c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(loss_history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(loss_history, label='Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Over Iterations')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
