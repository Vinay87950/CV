{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "portable-honolulu",
   "metadata": {},
   "source": [
    "## DEL-03 Programming Excercise - Multi-Layer Perceptron - Backward Propagation\n",
    "### (created by Prof. Dr.-Ing. Christian Bergler & Prof. Dr. Fabian Brunner)\n",
    "\n",
    "Documentation: **Python-Bibliothek Pandas** - https://pandas.pydata.org/docs/\n",
    "\n",
    "Documentation: **Numpy** - https://numpy.org/doc/\n",
    "\n",
    "Documentation: **Sklearn** - https://scikit-learn.org/stable/index.html\n",
    "\n",
    "Documentation: **Matplotlib** - Documentation: https://matplotlib.org/stable/index.html\n",
    "\n",
    "Documentation: **Matplotlib** - Graphics Gallery: https://matplotlib.org/2.0.2/gallery.html\n",
    "\n",
    "Additional Documentation: **Python Tutorial** - https://docs.python.org/3/tutorial/\n",
    "\n",
    "Additional Documentation: **Matthes Eric, \"Python crash course: A hands-on, project-based introduction to programming\"**, ISBN: 978-1-59327-603-4, ©2023 no starch press  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "775f02d0-0a43-4e74-ba20-2dd6e31d4c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf35aa-e63a-4614-82fd-bdd0930bc58e",
   "metadata": {},
   "source": [
    "### Task DEL-03-1 (Sigmoid Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c36ae757-3573-4d06-a17c-85dc653400fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-abraham",
   "metadata": {},
   "source": [
    "### Task DEL-03-2 (Softmax Activation Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374b557d-ae54-4d6f-a28b-9e77c7a7b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(O):\n",
    "    O_exp = np.exp(O - np.max(O, axis=1, keepdims=True))\n",
    "    partition = O_exp.sum(axis=1, keepdims=True)\n",
    "    return O_exp / partition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b155c-caf8-4e0a-88d8-360297444f30",
   "metadata": {},
   "source": [
    "### Task DEL-03-3 (Implementation Multi-Layer Perceptron for Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9712ba-b48e-4229-8a2e-4bdb22ce3317",
   "metadata": {},
   "source": [
    "In this and the next exercise, an `Multi-Layer Perceptron (Deep Feed Forward Neural Network)`  for classification is to be implemented from scratch. The topology of the network is to be specified using a list called `nodes_per_layer`. The $i$th entry specifies how many nodes the $i$th layer consists of. The number of layers can be arbitrary. The number of classes corresponds to the number of nodes in the output layer. \n",
    "\n",
    "Example: ``nodes_per_layer = [4,5,3]`` would realize a network with 4 nodes in the input layer, 5 nodes in the hidden layer and 3 nodes in the output layer.\n",
    "\n",
    "Now that forward propagation has already been implemented in the other exercise, model training is to be implemented using the gradient (descent) method. To do this, complete the following class ``DeepFeedForward``. The gradient calculation should be carried out using the backpropagation algorithm presented in the lecture. In addition to the implementation of the ``fit`` method, a modification of the ``forward`` method is recommended by saving the `inputs` and `activations of the hidden layers` calculated during the forward propagation. These are accessed in the course of back propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c61402c-a356-4072-9987-973fbc6762f7",
   "metadata": {},
   "source": [
    "#### Equation for Backpropagation (Recap!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3413ed4f-99b6-4514-9afa-07ff22db93e6",
   "metadata": {},
   "source": [
    "- Rekursive Berechnung der Größen $\\delta^{[l]}$:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\delta^{[L]}&=\\nabla_{\\hat{y}}L \\odot ({f^{[L]}})'(z^{[L]})~,\\\\[0.2cm]\n",
    "\\delta^{[l]}&={\\mathbf{W}^{[l+1]}}\\delta^{[l+1]}\\odot{(f^{[l]}})'(z^{[l]})~,\\quad l=L-1,\\ldots,1\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c6cae-e6f4-4660-aa60-8b4382140a8d",
   "metadata": {},
   "source": [
    "- Calculation of the partial derivatives according to the weights as a function of the variables $\\delta^{[l]}$:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial b_j^{[l]}}&=\\delta^{[l]}_j~,\\quad l=1,\\ldots,L\\\\[0.2cm]\n",
    "\\frac{\\partial L}{\\partial w^{[l]}_{kj}}&=h_k^{[l-1]}\\delta_j^{[l]}~,\\quad l=1,\\ldots,L~.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e799bd80-dae4-40d2-9cf8-44ae35d0b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFeedForward:\n",
    "    def __init__(self, nodes_per_layer, lr=1.0, num_iter = 100):\n",
    "        self.learning_rate = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.n_layers = len(nodes_per_layer) #number of layers\n",
    "        self.nodes_per_layer = nodes_per_layer #list containing the number of nodes for each layer\n",
    "        self.n_classes = nodes_per_layer[-1] #number of output units (=number of classes for classification)\n",
    "        self.weight_matrices = [] #in this list, the weight matrices will be stored\n",
    "        self.bias_vectors = [] #in this list, the bias vectors will be stored\n",
    "   \n",
    "    def initialize_weights(self):\n",
    "        \"\"\"\n",
    "        When this function is called, the weight matrices and bias vectors are \n",
    "        initialized with random normally distributed numbers and stored in the instance parameters weight_matrices and bias_vectors\n",
    "        For each layer (except the input layer), one weight matrix and one bias vector is needed.\n",
    "        The dimensions of the matrices depend on the number of units of the layers.\n",
    "        \"\"\" \n",
    "        self.weight_matrices = []\n",
    "        self.bias_vectors = []\n",
    "        #TODO\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        model function to perform the forward pass through the net for all samples in the batch X\n",
    "        \n",
    "        In each layer except the output layer, sigmoid activation is used. \n",
    "        In the output layer, softmax activation is used.\n",
    "        \n",
    "        :param X: batch of training data of dimension n_samples x n_features\n",
    "        :type X: numpy array\n",
    "        :return: array containing the predicted scores for all samples of the batch X (dimension: n_samples x n_classes)\n",
    "        :rtype: numpy array\n",
    "        \"\"\" \n",
    "        layer_inputs = []\n",
    "        layer_outputs = []\n",
    "        \n",
    "        #TODO\n",
    "        \n",
    "        self.layer_outputs = layer_outputs\n",
    "        self.layer_inputs = layer_inputs\n",
    "        \n",
    "        return H\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Model training using gradient descent optimization algorithm\n",
    "\n",
    "        :param X: batch of training data of dimension n_samples x n_features\n",
    "        :type X: numpy array\n",
    "        :param y: target values corresponding to records in X \n",
    "        :type y: numpy array\n",
    "        :return: List containing the values of the loss function after each iteration of Gradient descent\n",
    "        :rtype: list\n",
    "        \"\"\"\n",
    "        \n",
    "        loss_history = []\n",
    "        \n",
    "        #TODO\n",
    "        \n",
    "        return loss_history\n",
    "            \n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict classes based on the largest predicted class probability\n",
    "        \n",
    "        :param X: batch of data to be scored\n",
    "        :type X: numpy array\n",
    "        :return: predicted classes for the records in X\n",
    "        :rtype: numpy array\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-scroll",
   "metadata": {},
   "source": [
    "### Task DEL-03-4 (Testing Implemented Backward Propagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-status",
   "metadata": {},
   "source": [
    "- Create a new `DeepFeedForward` object with `4 input neurons, 10 hidden neurons, and 3 output neurons`\n",
    "- learning rate of `lr=0.2`, and maximum iterations `num_iter=300`\n",
    "- Initialize `weights` and `biases`\n",
    "- Train the model using `fit`\n",
    "- Evaluate using `predict` and `plot` (matplotlib) the `loss` curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "animal-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data \n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "identical-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "peaceful-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc1fe23-6071-4786-bb21-ee692dc080c0",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "\n",
    "- Train the `DeepFeedForward` neural network, using the implemented ``fit`` method and `plot` the progression of the loss function over time. How does the curve differ from the curve you observed with the `logistic regression` and the `softmax` regression? Explain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24b2455c-8260-40be-828b-06f100825f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45207810-203c-43cc-a155-6b2f4dd34a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af003097-e4e0-4c69-9b9a-281cd1d71a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
